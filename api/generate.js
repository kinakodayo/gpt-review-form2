export default async function handler(req, res) {
  const buffers = [];
  for await (const chunk of req) {
    buffers.push(chunk);
  }

  try {
    const bodyRaw = Buffer.concat(buffers).toString();
    const body = JSON.parse(bodyRaw);
    const prompt = body.prompt || "è‡ªç„¶ãªã‚¯ãƒã‚³ãƒŸæ–‡ã‚’1ã¤ä½œã£ã¦ãã ã•ã„";

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content: "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’ã‚‚ã¨ã«è‡ªç„¶ã§ä¸å¯§ãªæ—¥æœ¬èªã®Googleã‚¯ãƒã‚³ãƒŸæ–‡ã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚"
          },
          { role: "user", content: prompt }
        ],
        temperature: 0.7
      })
    });

    const data = await response.json();
    console.log("ğŸ” OpenAI API Response:", data); // â† ã“ã‚Œã‚’è¿½åŠ ï¼

    if (!response.ok) {
      return res.status(500).send("OpenAIã‚¨ãƒ©ãƒ¼: " + JSON.stringify(data));
    }

    const result =
      data.choices?.[0]?.message?.content ||
      data.error?.message ||
      "ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ";

    res.setHeader("Content-Type", "text/plain");
    res.status(200).send(result);

  } catch (error) {
    console.error("âŒ ã‚µãƒ¼ãƒãƒ¼å´ã‚¨ãƒ©ãƒ¼:", error);
    res.status(500).send("ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: " + error.message);
  }
}
